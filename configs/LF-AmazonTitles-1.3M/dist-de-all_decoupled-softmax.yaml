__dependency__: configs/dual-encoder.yaml, configs/LF-AmazonTitles-1.3M/dataset.yaml
expname: dist-de-all_decoupled-softmax_exp
desc: "Training dist-de-all (distributed dual-encoder with all labels) with decoupled-softmax loss"

# Network and loss parameters
net: dist-de-all
norm_embs: False
tau: 1
neg_type: none # dist-de-all nets uses all labels as negatives, so no need to sample negatives in data loading
loss_criterion: decoupled-softmax
loss_sample: True

# Training parameters
bsz: 3000
gc_bsz: 3000
lr: 3.e-4
dropout: 0